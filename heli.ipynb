{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import theano\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from ple.games.pixelcopter import Pixelcopter\n",
    "from ple import PLE\n",
    "import pygame\n",
    "import numpy as np\n",
    "import time\n",
    "from IPython.display import clear_output\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "\n",
    "# note: uncomment below lines and comment load_model \n",
    "# line if you want to train from scratch\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Dense(20, input_dim=5, activation=\"relu\"))\n",
    "# model.add(Dense(10, activation=\"relu\"))\n",
    "# model.add(Dense(2, activation=\"linear\"))\n",
    "# adam = Adam(lr=0.0001)\n",
    "# model.compile(loss='mse', optimizer=adam)\n",
    "\n",
    "model = load_model(\"w_2018-08-16_11_44_21.189374.h5py\") \n",
    "# loads most recently trained weights, Aug 16 11:44am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "game = Pixelcopter(width=256, height=256)\n",
    "p = PLE(game, fps=150, display_screen=False)\n",
    "\n",
    "reward = 0.0\n",
    "p.init()\n",
    "count = 0\n",
    "\n",
    "epochs = 10000\n",
    "rewards = np.zeros((1,epochs))[0]\n",
    "gamma = 0.999\n",
    "epsilon = 0.001\n",
    "batchSize = 300\n",
    "buffer = 600\n",
    "replay = []\n",
    "i = 0\n",
    "h = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainAgent(epochs, rewards, gamma, epsilon, batchSize, buffer, replay):\n",
    "    \n",
    "    for i in range(epochs):\n",
    "\n",
    "        p.reset_game()\n",
    "\n",
    "        while (not p.game_over()):\n",
    "            state = game.getGameState()\n",
    "            stateLst = np.array([[state[k] for k in state]])\n",
    "            qval = model.predict(stateLst)\n",
    "            if (random.random() < epsilon):\n",
    "                action = np.random.randint(0,2)\n",
    "                print(\"here \", action)\n",
    "            else:\n",
    "                action = np.argmax(qval)\n",
    "\n",
    "            actionList = p.getActionSet()\n",
    "            reward = p.act(actionList[action])\n",
    "\n",
    "            newState = game.getGameState()\n",
    "            newStateLst = np.array([[newState[k] for k in state]])\n",
    "\n",
    "            if (len(replay) < buffer):\n",
    "                replay.append((stateLst, action, reward, newStateLst))\n",
    "            else:\n",
    "                if h < buffer-1:\n",
    "                    h += 1\n",
    "                else:\n",
    "                    h = 0\n",
    "                replay[h] = (stateLst, action, reward, newStateLst)\n",
    "                minibatch = random.sample(replay, batchSize)\n",
    "                X_train = np.empty((0,5))\n",
    "                y_train = np.empty((0,2))\n",
    "\n",
    "                for memory in minibatch:\n",
    "                    old_state, action, reward, new_state = memory\n",
    "                    oldQ = model.predict(old_state)\n",
    "                    newQ = model.predict(newStateLst)\n",
    "                    maxQ = np.max(newQ)\n",
    "\n",
    "                    if p.game_over():\n",
    "                        update = reward\n",
    "                    else:\n",
    "                        update = reward + (gamma * maxQ)\n",
    "                    y = np.copy(oldQ)\n",
    "                    y[0][action] = update\n",
    "                    X_train = np.append(X_train, old_state, axis=0)\n",
    "                    y_train = np.append(y_train, y, axis=0)\n",
    "\n",
    "                model.fit(X_train, y_train, batch_size=batchSize)\n",
    "\n",
    "            pygame.display.update()\n",
    "            print(i)\n",
    "            clear_output(wait=True)\n",
    "\n",
    "\n",
    "        rewards[i] = p.score()\n",
    "        i += 1\n",
    "        if epsilon > 0.0001: #decrement epsilon over time\n",
    "            epsilon -= (1/epochs)\n",
    "\n",
    "        if i % 5000 == 0:    \n",
    "            f = \"w_\" + str(datetime.datetime.now()).replace(\" \", \"_\").replace(\":\", \"_\") + \".h5py\"\n",
    "            model.save(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def testAgent(epochs):\n",
    "    p.init()\n",
    "    game.screen = pygame.display.set_mode(game.getScreenDims(), 0, 32)\n",
    "    game.clock = pygame.time.Clock()\n",
    "    i = 0\n",
    "    while (i < epochs):\n",
    "    \n",
    "        p.reset_game()\n",
    "\n",
    "        while (not p.game_over()):\n",
    "            try:\n",
    "                state = game.getGameState()\n",
    "                stateLst = np.array([[state[k] for k in state]])\n",
    "                qval = model.predict(stateLst)\n",
    "                action = np.argmax(qval)\n",
    "                actionList = p.getActionSet()\n",
    "                reward = p.act(actionList[action])\n",
    "\n",
    "                pygame.display.update()\n",
    "            \n",
    "            except:\n",
    "                break\n",
    "\n",
    "        i += 1\n",
    "\n",
    "testAgent(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = \"w_\" + str(datetime.datetime.now()).replace(\" \", \"_\").replace(\":\", \"_\") + \".h5py\"\n",
    "model.save(f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
